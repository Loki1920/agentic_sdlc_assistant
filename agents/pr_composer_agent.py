from __future__ import annotations

import asyncio
import re
from typing import Optional

from agents.base_agent import BaseAgent
from config.settings import settings
from app_logging.activity_logger import ActivityLogger
from mcp_client.client_factory import filter_github_tools, get_mcp_client
from prompts.pr_composer_prompt import PR_TITLE_SYSTEM
from schemas.pr import PRCompositionResult, PRStatus
from schemas.workflow_state import WorkflowPhase, WorkflowState

logger = ActivityLogger("pr_composer_agent")

AI_DISCLAIMER = """
---
> ⚠️ **This PR was generated by AI (Claude via AWS Bedrock) and requires thorough human review
> before merging. Verify all logic, test coverage, and edge cases independently.**
>
> _Generated by AI Agentic SDLC Assistant_
""".strip()


def _build_pr_body(state: dict) -> str:
    ticket_id = state.get("ticket_id", "")
    ticket = state.get("ticket_context")
    plan = state.get("implementation_plan")
    code = state.get("code_proposal")
    tests = state.get("test_suggestions")

    parts = [f"## {ticket_id}: {ticket.title if ticket else 'AI-Generated PR'}", ""]

    # Jira link
    if settings.jira_url and ticket_id:
        parts += [
            f"**Jira Ticket:** [{ticket_id}]({settings.jira_url}/browse/{ticket_id})", ""
        ]

    # Summary
    if plan:
        parts += ["## Summary", plan.summary, ""]

    # Implementation Plan
    if plan and plan.implementation_steps:
        parts += ["## Implementation Plan", ""]
        for step in plan.implementation_steps:
            parts.append(
                f"**Step {step.step_number}: {step.title}**  "
                f"\n{step.description}"
                + (
                    f"\nFiles: `{'`, `'.join(step.affected_files)}`"
                    if step.affected_files
                    else ""
                )
            )
            parts.append("")

        if plan.risk_level:
            parts.append(f"**Risk Level:** {plan.risk_level.value.upper()} — {plan.risk_rationale}")
        if plan.breaking_changes:
            parts.append("⚠️ **Breaking Changes: YES**")
        if plan.database_migrations_required:
            parts.append("⚠️ **Database Migrations Required: YES**")
        if plan.deployment_considerations:
            parts.append("\n**Deployment Notes:**")
            for note in plan.deployment_considerations:
                parts.append(f"- {note}")
        parts.append("")

    # Code Changes Summary
    if code and code.file_changes:
        parts += ["## Proposed Code Changes", ""]
        for fc in code.file_changes:
            parts.append(f"### `{fc.file_path}` ({fc.change_type.value})")
            parts.append(fc.rationale)
            if fc.proposed_content:
                lang = _detect_lang(fc.file_path)
                parts.append(f"```{lang}")
                parts.append(fc.proposed_content[:2000])
                if len(fc.proposed_content) > 2000:
                    parts.append("... (truncated — see full diff in files)")
                parts.append("```")
            parts.append("")

        if code.new_dependencies:
            parts.append("**New Dependencies:**")
            for dep in code.new_dependencies:
                parts.append(f"- `{dep}`")
            parts.append("")

    # Test Suggestions
    if tests and tests.test_cases:
        parts += ["## Test Suggestions", ""]
        parts.append(f"Framework: `{tests.framework}`")
        parts.append("")
        for tc in tests.test_cases[:10]:
            edge = " *(edge case)*" if tc.edge_case else ""
            parts.append(f"- **{tc.test_name}**{edge} — {tc.description}")
        if len(tests.test_cases) > 10:
            parts.append(f"- _(+{len(tests.test_cases) - 10} more test cases)_")
        parts.append("")

    # Confluence Documentation References
    confluence = state.get("confluence_context")
    if confluence and confluence.pages_found:
        parts += ["## Confluence Documentation References", ""]
        for page in confluence.pages_found:
            parts.append(f"- [{page.title}]({page.url}) — {page.relevance_reason}")
        parts.append("")
        if confluence.doc_update_suggestions:
            parts += ["**Suggested Documentation Updates:**", ""]
            for suggestion in confluence.doc_update_suggestions:
                parts.append(f"- {suggestion}")
            parts.append("")

    # Confidence scores
    confidence_items = []
    if plan:
        confidence_items.append(f"Plan: {plan.confidence_score:.0%}")
    if code:
        confidence_items.append(f"Code: {code.confidence_score:.0%}")
    if tests:
        confidence_items.append(f"Tests: {tests.confidence_score:.0%}")
    if confidence_items:
        parts += ["## AI Confidence Scores", ", ".join(confidence_items), ""]

    parts.append(AI_DISCLAIMER)
    return "\n".join(parts)


def _detect_lang(file_path: str) -> str:
    ext_map = {
        ".py": "python", ".js": "javascript", ".ts": "typescript",
        ".go": "go", ".java": "java", ".rb": "ruby", ".rs": "rust",
        ".sh": "bash", ".yml": "yaml", ".yaml": "yaml", ".json": "json",
        ".tf": "hcl", ".sql": "sql",
    }
    for ext, lang in ext_map.items():
        if file_path.endswith(ext):
            return lang
    return ""


async def _create_branch(tools: list, owner: str, repo: str, branch_name: str, base_branch: str) -> bool:
    """Create a new branch from base_branch."""
    # Get base SHA first
    get_branch = next(
        (t for t in tools if "get_branch" in t.name.lower() or ("branch" in t.name.lower() and "get" in t.name.lower())),
        None,
    )
    create_branch = next(
        (t for t in tools if "create_branch" in t.name.lower()),
        None,
    )

    if not create_branch:
        logger.warning("github_create_branch_tool_not_found")
        return False

    try:
        base_sha = ""
        if get_branch:
            branch_data = await get_branch.ainvoke({"owner": owner, "repo": repo, "branch": base_branch})
            base_sha = branch_data.get("commit", {}).get("sha", "") if isinstance(branch_data, dict) else ""

        kwargs = {"owner": owner, "repo": repo, "branch": branch_name}
        if base_sha:
            kwargs["from_branch"] = base_branch
        await create_branch.ainvoke(kwargs)
        return True
    except Exception as exc:
        logger.warning("github_create_branch_failed", error=str(exc))
        return False


async def _push_implementation_file(
    tools: list,
    owner: str,
    repo: str,
    branch_name: str,
    ticket_id: str,
    pr_body: str,
) -> None:
    """Push an IMPLEMENTATION_PLAN.md file to the branch."""
    push_tool = next(
        (t for t in tools if "create_or_update_file" in t.name.lower() or "push_files" in t.name.lower()),
        None,
    )
    if not push_tool:
        return

    try:
        import base64
        content = base64.b64encode(pr_body.encode()).decode()
        await push_tool.ainvoke({
            "owner": owner,
            "repo": repo,
            "path": f"ai_proposals/{ticket_id}/IMPLEMENTATION_PLAN.md",
            "message": f"chore({ticket_id}): add AI-generated implementation plan",
            "content": content,
            "branch": branch_name,
        })
    except Exception as exc:
        logger.warning("github_push_file_failed", error=str(exc))


async def _create_pull_request(
    tools: list,
    owner: str,
    repo: str,
    title: str,
    body: str,
    head_branch: str,
    base_branch: str,
    draft: bool,
    reviewers: list[str],
) -> dict:
    create_pr = next(
        (t for t in tools if "create_pull_request" in t.name.lower()),
        None,
    )
    if not create_pr:
        raise RuntimeError("create_pull_request tool not found in GitHub MCP")

    result = await create_pr.ainvoke({
        "owner": owner,
        "repo": repo,
        "title": title,
        "body": body,
        "head": head_branch,
        "base": base_branch,
        "draft": draft,
    })
    return result if isinstance(result, dict) else {}


async def _do_create_pr(state: dict) -> PRCompositionResult:
    ticket_id = state["ticket_id"]
    ticket = state.get("ticket_context")
    owner = settings.github_repo_owner
    repo = settings.github_repo_name
    base_branch = settings.github_base_branch

    # Sanitise branch name
    safe_id = re.sub(r"[^a-zA-Z0-9_-]", "-", ticket_id).lower()
    branch_name = f"ai/{safe_id}"

    pr_title = f"feat({ticket_id}): {ticket.title[:50] if ticket else ticket_id} [AI]"
    pr_body = _build_pr_body(state)

    async with get_mcp_client() as client:
        all_tools = await client.get_tools()
        gh_tools = filter_github_tools(all_tools)

        # Create branch
        branch_created = await _create_branch(gh_tools, owner, repo, branch_name, base_branch)

        # Push implementation plan file to branch
        if branch_created:
            await _push_implementation_file(gh_tools, owner, repo, branch_name, ticket_id, pr_body)

        # Create draft PR
        reviewers = settings.default_reviewers_list
        pr_data = await _create_pull_request(
            gh_tools, owner, repo,
            title=pr_title,
            body=pr_body,
            head_branch=branch_name if branch_created else base_branch,
            base_branch=base_branch,
            draft=True,
            reviewers=reviewers,
        )

    pr_url = pr_data.get("html_url") or pr_data.get("url")
    pr_number = pr_data.get("number")

    return PRCompositionResult(
        ticket_id=ticket_id,
        status=PRStatus.CREATED if pr_url else PRStatus.FAILED,
        pr_url=pr_url,
        pr_number=pr_number,
        branch_name=branch_name,
        base_branch=base_branch,
        pr_title=pr_title,
        pr_body=pr_body,
        draft=True,
        reviewers_requested=reviewers,
        jira_ticket_linked=bool(settings.jira_url),
        raw_mcp_output=pr_data,
    )


class PRComposerAgent(BaseAgent):
    def run(self, state: WorkflowState) -> dict:
        ticket_id = state["ticket_id"]
        run_id = state["run_id"]

        self.logger.info(
            "agent_node_entered",
            ticket_id=ticket_id,
            run_id=run_id,
            phase=WorkflowPhase.COMPOSING_PR,
        )

        if settings.dry_run:
            self.logger.info("dry_run_skip_pr_creation", ticket_id=ticket_id, run_id=run_id)
            pr_body = _build_pr_body(dict(state))
            return {
                "pr_result": PRCompositionResult(
                    ticket_id=ticket_id,
                    status=PRStatus.SKIPPED,
                    pr_title=f"[DRY RUN] {ticket_id}",
                    pr_body=pr_body,
                    draft=True,
                ),
                "current_phase": WorkflowPhase.COMPLETED,
            }

        try:
            pr_result = self.run_async(_do_create_pr(dict(state)))

            self.logger.info(
                "github_pr_created",
                ticket_id=ticket_id,
                run_id=run_id,
                pr_url=pr_result.pr_url,
                pr_number=pr_result.pr_number,
            )

            return {
                "pr_result": pr_result,
                "current_phase": WorkflowPhase.COMPLETED,
                "mcp_tool_calls": [{"tool": "github_create_pull_request", "pr_number": pr_result.pr_number}],
            }

        except Exception as exc:
            self.logger.error("github_pr_failed", exc=exc, ticket_id=ticket_id, run_id=run_id)
            return {
                "pr_result": PRCompositionResult(
                    ticket_id=ticket_id,
                    status=PRStatus.FAILED,
                    pr_title=f"[FAILED] {ticket_id}",
                    error_message=str(exc),
                ),
                "current_phase": WorkflowPhase.FAILED,
                "errors": [f"pr_composer: {exc}"],
            }


_agent = PRComposerAgent()


def pr_composer_node(state: WorkflowState) -> dict:
    return _agent.run(state)
